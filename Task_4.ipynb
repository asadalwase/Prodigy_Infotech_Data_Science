{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f982b2",
   "metadata": {},
   "source": [
    "# Analyze and visualize sentiment patterns in social media data to understand public opinion and attitudes towards specific topics or brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e01bde23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wordcloud) (10.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wordcloud) (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->wordcloud) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->wordcloud) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->wordcloud) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->wordcloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amaan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73fb96b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfigure_factory\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mff\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m## ML Modelling ## \u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline \n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer \n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## DATA ## \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "## NLP ##\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "## Visualization ## \n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt  \n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "## ML Modelling ## \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26490b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['ID', 'Entity', 'Sentiment', 'Content']\n",
    "train_df = pd.read_csv('twitter_training.csv', names=col_names)\n",
    "test_df = pd.read_csv('twitter_training.csv', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7258fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76964a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=['Content'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f5b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Sentiment'] = train_df['Sentiment'].replace('Irrelevant', 'Neutral')\n",
    "test_df['Sentiment'] = test_df['Sentiment'].replace('Irrelevant', 'Neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196bf3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = train_df['Sentiment'].value_counts().sort_index()\n",
    "\n",
    "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "sentiment_colors = ['red', 'grey', 'green']\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=sentiment_counts.index, \n",
    "                             values=sentiment_counts.values,\n",
    "                             textinfo='percent+value+label',\n",
    "                             marker_colors=sentiment_colors,\n",
    "                             textposition='auto',\n",
    "                             hole=.3)])\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Sentiment Distribution',\n",
    "    template='plotly_white',\n",
    "    xaxis=dict(\n",
    "        title='Sources',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of Posts in Twitter',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_color='black', \n",
    "                  marker_line_width=1.5, \n",
    "                  opacity=0.8)\n",
    " \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_entity_counts = train_df['Entity'].value_counts().sort_values(ascending=False)[:10]\n",
    "\n",
    "fig = px.bar(x=top10_entity_counts.index, \n",
    "             y=top10_entity_counts.values,\n",
    "             color=top10_entity_counts.values,\n",
    "             text=top10_entity_counts.values,\n",
    "             color_continuous_scale='Blues')\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Top 10 Twitter Entity Distribution',\n",
    "    template='plotly_white',\n",
    "    xaxis=dict(\n",
    "        title='Entity',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of Posts in Twitter',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_color='black', \n",
    "                  marker_line_width=1.5, \n",
    "                  opacity=0.8)\n",
    " \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_entity_df = train_df['Entity'].value_counts().sort_values(ascending=False)[:3]\n",
    "top3_entity = top3_entity_df.index.tolist()\n",
    "sentiment_by_entity = train_df.loc[train_df['Entity'].isin(top3_entity)].groupby('Entity')['Sentiment'].value_counts().sort_index()\n",
    "\n",
    "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "sentiment_colors = ['red', 'grey', 'green']\n",
    "\n",
    "row_n = 1\n",
    "col_n = 3\n",
    "\n",
    "fig = make_subplots(rows=row_n, cols=col_n, \n",
    "                    specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],\n",
    "                    subplot_titles=top3_entity)\n",
    "\n",
    "for i, col in enumerate(top3_entity):\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=sentiment_labels, \n",
    "                values=sentiment_by_entity[col].values, \n",
    "                textinfo='percent+value+label',\n",
    "                marker_colors=sentiment_colors,\n",
    "                textposition='auto',\n",
    "                name=col),\n",
    "            row=int(i/col_n)+1, col=int(i%col_n)+1)\n",
    "    \n",
    "fig.update_traces(marker_line_color='black', \n",
    "                  marker_line_width=1.5, \n",
    "                  opacity=0.8)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047adbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_string(sentences): \n",
    "    sentence = ''\n",
    "    for words in sentences:\n",
    "        sentence += words\n",
    "    sentence = re.sub('[^A-Za-z0-9 ]+', '', sentence)\n",
    "    sentence = re.sub(r'http\\S+', '', sentence)\n",
    "    sentence = sentence.lower()\n",
    "    return sentence \n",
    "\n",
    "def get_word(sentence):\n",
    "    return nltk.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "\n",
    "def remove_stopword(word_tokens):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for word in word_tokens:\n",
    "        if word not in stopword_list: \n",
    "            filtered_tokens.append(word) \n",
    "    return filtered_tokens \n",
    "\n",
    "def lemmatize_words(filtered_tokens):\n",
    "    lemm = WordNetLemmatizer() \n",
    "    cleaned_tokens = [lemm.lemmatize(word) for word in filtered_tokens]\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_df(cleaned_tokens): \n",
    "    fdist = nltk.FreqDist(cleaned_tokens)\n",
    "    freq_df = pd.DataFrame.from_dict(fdist, orient='index')\n",
    "    freq_df.columns = ['Frequency']\n",
    "    freq_df.index.name = 'Term'\n",
    "    freq_df = freq_df.sort_values(by=['Frequency'], ascending=False)\n",
    "    freq_df = freq_df.reset_index()\n",
    "    return freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(series):\n",
    "    all_string = get_all_string(series)\n",
    "    words = get_word(all_string)\n",
    "    filtered_tokens = remove_stopword(words)\n",
    "    cleaned_tokens = lemmatize_words(filtered_tokens)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_text_distribution(x_df, y_df, color, title, xaxis_text, yaxis_text):\n",
    "    \n",
    "    fig = px.bar(x=x_df, \n",
    "                y=y_df,\n",
    "                color=y_df,\n",
    "                text=y_df,\n",
    "                color_continuous_scale=color)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=title,\n",
    "        template='plotly_white',\n",
    "        xaxis=dict(\n",
    "            title=xaxis_text,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=yaxis_text,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker_line_color='black', \n",
    "                    marker_line_width=1.5, \n",
    "                    opacity=0.8)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(freq_df, title, color):\n",
    "    \n",
    "    data = freq_df.set_index('Term').to_dict()['Frequency']\n",
    "    \n",
    "    plt.figure(figsize = (20,15))\n",
    "    wc = WordCloud(width=800, \n",
    "               height=400, \n",
    "               max_words=100,\n",
    "               colormap= color,\n",
    "               max_font_size=200,\n",
    "               min_font_size = 1 ,\n",
    "               random_state=8888, \n",
    "               background_color='white').generate_from_frequencies(data)\n",
    "    \n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = preprocess(train_df.loc[train_df['Sentiment'] == 'Positive']['Content'])\n",
    "positive_words_df = create_freq_df(positive_words)\n",
    "top10_positive_words = positive_words_df[:10]\n",
    "\n",
    "plot_text_distribution(top10_positive_words['Term'], top10_positive_words['Frequency'],\n",
    "                  'Greens', 'Top 10 Positive Sentiment Text Distribution', 'Text', 'Number of Texts')\n",
    "create_wordcloud(positive_words_df, 'Positive Sentiment Text Distribution', 'BuGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = preprocess(train_df.loc[train_df['Sentiment'] == 'Negative']['Content'])\n",
    "negative_words_df = create_freq_df(negative_words)\n",
    "top10_negative_words = negative_words_df[:10]\n",
    "\n",
    "plot_text_distribution(top10_negative_words['Term'], top10_negative_words['Frequency'],\n",
    "                  'Reds', 'Top 10 Negative Sentiment Text Distribution', 'Text', 'Number of Texts')\n",
    "create_wordcloud(negative_words_df, 'Negative Sentiment Text Distribution', 'OrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc81db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_words = preprocess(train_df.loc[train_df['Sentiment'] == 'Neutral']['Content'])\n",
    "neutral_words_df = create_freq_df(neutral_words)\n",
    "top10_neutral_words = neutral_words_df[:10]\n",
    "\n",
    "plot_text_distribution(top10_neutral_words['Term'], top10_neutral_words['Frequency'],\n",
    "                  'Greys', 'Top 10 Neutral Sentiment Text Distribution', 'Text', 'Number of Texts')\n",
    "create_wordcloud(neutral_words_df, 'Neutral Sentiment Text Distribution', 'binary_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7bd6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff12fd-ecd1-4130-b5c6-1fa911f9540c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320b42b-6e4c-44a3-8499-5a5eab21fabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c7224-205f-47cc-ac88-db3ae9c3e814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
